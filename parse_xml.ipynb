{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do:\n",
    "- figure out how to save graph locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### references:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing: sys.stdout.write(f'\\r  ...progress: {curRow * tilesY} / {tilesX * tilesY} ({pct:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from lxml.etree import XMLSyntaxError\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import networkx as nx\n",
    "from natsort import index_natsorted, order_by_index\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  progress:  1000000  rows\n",
      "broke\n"
     ]
    }
   ],
   "source": [
    "source = \"dblp.xml\" #dataset of publications\n",
    "dtd = etree.DTD(file=\"dblp.dtd\") #read DTD\n",
    "publication_data = [] #fill this list with pairs of author/title\n",
    "counter = 0\n",
    "bad_titles = [\"Home Page\", \"Title Page\", \"Welcome message.\", \"Workshop preface.\", \"Vorwort.\", \"The\", \"The \", \"Session Summary.\", \"Reviewers.\", \"Program Committee.\", \n",
    "    \"Preface.\", \"Organizing Committee.\", \"Workshop Organization.\", \"Workshop Organizers' Message.\", \"Title Page.\", \"Steering Committee.\", \"Session details: Keynote Address.\",\n",
    "    \"S\"]\n",
    "#iterate through nodes\n",
    "for event, element in etree.iterparse(source, load_dtd=True):\n",
    "    title = \"\"\n",
    "    author_list = []\n",
    "    year = 0\n",
    "    #iterate through children: author, title, year, etc.\n",
    "    for child in element:\n",
    "        if child.tag == \"author\":\n",
    "            counter+=1\n",
    "        elif child.tag == \"title\":\n",
    "            title = str(child.text)\n",
    "            if title in bad_titles:\n",
    "                title = \"\";\n",
    "            # break\n",
    "    if counter % 10000 == 0:\n",
    "        sys.stdout.write(f'\\r  progress:  {counter}  rows')\n",
    "    if counter >= 1000000:\n",
    "        print(\"\\nbroke\")\n",
    "        break\n",
    "#create dataframe\n",
    "publication_df = pd.DataFrame(publication_data)\n",
    "\n",
    "element.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  progress:  1000000  rowsbroke\n"
     ]
    }
   ],
   "source": [
    "source = \"dblp.xml\" #dataset of publications\n",
    "dtd = etree.DTD(file=\"dblp.dtd\") #read DTD\n",
    "publication_data = [] #fill this list with pairs of author/title\n",
    "edge_list = [] #fill this with edges\n",
    "counter = 0\n",
    "bad_titles = [\"Home Page\", \"Title Page\", \"Welcome message.\", \"Workshop preface.\", \"Vorwort.\", \"The\", \"The \", \"Session Summary.\", \"Reviewers.\", \"Program Committee.\", \n",
    "    \"Preface.\", \"Organizing Committee.\", \"Workshop Organization.\", \"Workshop Organizers' Message.\", \"Title Page.\", \"Steering Committee.\", \"Session details: Keynote Address.\",\n",
    "    \"S\"]\n",
    "#iterate through nodes\n",
    "for event, element in etree.iterparse(source, load_dtd=True):\n",
    "    title = \"\"\n",
    "    author_list = []\n",
    "    year = 0\n",
    "    #iterate through children: author, title, year, etc.\n",
    "    for child in element:\n",
    "        if child.tag == \"author\":\n",
    "            author_list.append(str(child.text))\n",
    "        elif child.tag == \"title\":\n",
    "            title = str(child.text)\n",
    "            if title in bad_titles:\n",
    "                title = \"\"; \n",
    "        elif child.tag == \"year\":\n",
    "            year = int(child.text)\n",
    "            for author in author_list:\n",
    "                publication_data.append({\"Author\" : author.strip(), \"Title\" : title.strip(), \"Year\" : year}) #add author/title/year pair to data list\n",
    "            if len(author_list) > 1:\n",
    "                edge_list.append(author_list)\n",
    "            counter += 1\n",
    "            break\n",
    "    if counter % 10000 == 0:\n",
    "        sys.stdout.write(f'\\r  progress:  {counter}  rows')\n",
    "    if counter > 1000000:\n",
    "        print(\"\\nbroke\")\n",
    "        break\n",
    "#create dataframe\n",
    "publication_df = pd.DataFrame(publication_data)\n",
    "edges_df = pd.DataFrame(edge_list)\n",
    "element.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2951926\n",
      "777398\n"
     ]
    }
   ],
   "source": [
    "publication_df.to_csv('data.csv')\n",
    "edges_df.to_csv('edges.csv')\n",
    "print(len(publication_df))\n",
    "print(len(edges_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting CSV to graph: adding authors as nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_df = pd.read_csv(\"data.csv\")\n",
    "publication_df = publication_df.reindex(index=order_by_index(publication_df.index, index_natsorted(publication_df['Author'], reverse=False))) # sorting by author name\n",
    "publication_df.to_csv('data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique authors: 965885\n"
     ]
    }
   ],
   "source": [
    "author_graph = nx.Graph()\n",
    "publication_df = pd.read_csv(\"data.csv\")\n",
    "author_graph.add_node(publication_df[\"Author\"][0], Publications = {publication_df[\"Title\"][0]})\n",
    "for row in range(1, len(publication_df)):\n",
    "    author = publication_df[\"Author\"][row]\n",
    "    if author == publication_df[\"Author\"][row-1]:\n",
    "        author_graph.nodes[author][\"Publications\"].add(publication_df[\"Title\"][row]) #adding title to list of publications from that author\n",
    "    else:\n",
    "        author_graph.add_node(author, Publications = {publication_df[\"Title\"][row]}) #adding author to graph with title to attibute\n",
    "print(\"Number of unique authors: \" + str(len(author_graph.nodes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting CSV by title and url (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mail4\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "publication_df1 = pd.read_csv(\"data.csv\")\n",
    "# publication_df1 = publication_df1.reindex(index=order_by_index(publication_df1.index, index_natsorted(publication_df1['Url'], reverse=False)))\n",
    "publication_df1 = publication_df1.reindex(index=order_by_index(publication_df1.index, index_natsorted(publication_df1['Title'], reverse=True)))\n",
    "publication_df1.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding edges for authors that share title (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 0\n",
    "while (publication_df[\"Title\"][row] != \"None\"): #for all elements with a title\n",
    "# while row < len(publication_df2)-5:\n",
    "    next = 1\n",
    "    current_author = publication_df[\"Author\"][row]\n",
    "    co_authors = [current_author] #list of coauthors\n",
    "    while publication_df[\"Title\"][row] ==  publication_df[\"Title\"][row + next]: #find all authors with same title\n",
    "        if (current_author !=  publication_df[\"Author\"][row + next]) and (publication_df2[\"Year\"][row] ==  publication_df[\"Year\"][row + next]): #make sure no edges between same author\n",
    "            co_authors.append(publication_df[\"Author\"][row + next]) #add to list of co-authors\n",
    "            print(publication_df[\"Title\"][row])\n",
    "        next += 1\n",
    "    author_graph.add_edges_from(list(combinations(co_authors, 2))) #add edges between all coauthors\n",
    "    row += 1\n",
    "print(\"Last row with a title: \" + str(row))\n",
    "print(\"Number of edges: \" + str(len(author_graph.edges)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding edges for authors that share URL (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 566\n"
     ]
    }
   ],
   "source": [
    "row = 352356\n",
    "while row < len(publication_df) - 1: #for all elements with no title\n",
    "    next = 1\n",
    "    co_authors = [publication_df[\"Author\"][row]] #list of coauthors\n",
    "    while publication_df[\"Url\"][row] ==  publication_df[\"Url\"][row + next]: #find all authors with same title\n",
    "        if (publication_df[\"Author\"][row] !=  publication_df[\"Author\"][row + next]) and (publication_df2[\"Year\"][row] ==  publication_df[\"Year\"][row + next]): #make sure no edges between same author\n",
    "            co_authors.append(publication_df[\"Author\"][row + next]) #add to list of co-authors\n",
    "        next += 1\n",
    "    author_graph.add_edges_from(list(combinations(co_authors, 2))) #add edges between all coauthors\n",
    "    row += 1\n",
    "print(\"Number of edges: \" + str(len(author_graph.edges)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding edges based on CSV of edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_list = pd.read_csv(\"edges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[(1, 2), (1, 3), (2, 3)]\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from([1, 2, 3])\n",
    "print(G.nodes)\n",
    "G.add_edges_from(list(combinations([1, 2, 3], 2)))\n",
    "print(G.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  rows processed: 777000"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for row in edges_list.iterrows():\n",
    "    i = 1\n",
    "    coauthors = []\n",
    "    while (type(row[1][i])) == str and (i < 15):\n",
    "        coauthors.append(row[1][i])\n",
    "        i += 1\n",
    "    author_graph.add_edges_from(list(combinations(coauthors, 2)))\n",
    "    count+=1\n",
    "    if count % 1000 == 0:\n",
    "        sys.stdout.write(f'\\r  rows processed: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Wei Wang', 771), ('Yang Liu', 727), ('Lei Zhang', 726), ('Yu Zhang', 669), ('Wei Zhang', 653), ('Wei Li', 650), ('Jing Li', 634), ('Lei Wang', 621), ('Xin Li', 617), ('Wei Liu', 613)]\n",
      "\n",
      "['Bülent Abali', 'Bülent Bolat', 'Bülent Çatay', 'Bülent Dal', 'Bülent Durak', 'Bülent Haznedar', 'Bülent Karasözen', 'Bülent Keskinler', 'Bülent Möller', 'Bülent Örencik']\n"
     ]
    }
   ],
   "source": [
    "print(str(sorted(author_graph.degree, key=lambda x: x[1], reverse=True)[0:10]) + \"\\n\") # 10 authors with most coauthors\n",
    "\n",
    "# google pagerank algorithm (error with this)\n",
    "pageranks = nx.pagerank(author_graph) # A dictionary\n",
    "print(sorted(pageranks, key=lambda x: x[1], reverse=True)[0:10]) # 10 authors with highest pageranks score (sharing publications with more important authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save graph as a graphml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Publications': {'3D SLAM for Scenes with Repetitive Texture Inside Tokamak Chamber.',\n",
       "  '3D model retrieval based on orthogonal projections.',\n",
       "  '50 nA, 1 V nanowatt resistor-free compact CMOS current references.',\n",
       "  'A Conflict Detection Method for IPv6 Time-Based Firewall Policy.',\n",
       "  'A Cross-Culture Study on Multimodal Emotion Recognition Using Deep Learning.',\n",
       "  'A Data-Centric Storage Approach for Efficient Query of Large-Scale Smart Grid.',\n",
       "  'A Density-Based Seed-Centric Community Detection Algorithm.',\n",
       "  'A Diagnostic Knowledge Model of Wind Turbine Fault.',\n",
       "  'A Honeycomb Artifacts Removal and Super Resolution Method for Fiber-Optic Images.',\n",
       "  'A Key-Frame Selection Method for Semi-automatic 2D-to-3D Conversion.',\n",
       "  'A Keyword-Driven Data Service Composition Sequence Generation Approach on Ad-Hoc Data Query.',\n",
       "  'A Keyword-Driven Data Service Mashup Plan Generation Approach for Ad-Hoc Data Query.',\n",
       "  'A Method for Evaluating the Sensitivity of Signal Features in Pattern Recognition Based on Neural Network.',\n",
       "  'A Method of MOBA Game Lineup Recommendation Based on NSGA-II.',\n",
       "  'A Multimedia Application Adaption Layer (MAAL) Protocol.',\n",
       "  'A New Scheme for Essential Proteins Identification in Dynamic Weighted Protein-Protein Interaction Networks.',\n",
       "  'A Novel Effective Dimensionality Reduction Algorithm for Water Chiller Fault Data.',\n",
       "  'A Novel Frequency Coded Orthogonal UWB Pulse Design for Narrowband Interference Suppression.',\n",
       "  'A Novel Method of APK-Based Automated Execution and Traversal with a Trusted Execution Environment.',\n",
       "  'A P2P Camera System with New Consistent Labeling Method Involving Only Simple Geometric Operations.',\n",
       "  'A Query Approach of Supporting Variable Physical Window in Large-Scale Smart Grid.',\n",
       "  'A Remote Online Condition Monitoring and Intelligent Diagnostic System for Wind Turbine.',\n",
       "  'A SOC Design for AVS Video Decoding.',\n",
       "  'A Service Continuity Management Method for MEC-Assisted C-V2X Applications.',\n",
       "  'A Survey on Side-Channel Attacks of Strong PUF.',\n",
       "  'A System for Web-Based Interactive Real-Time Data Visualization and Analysis.',\n",
       "  'A Web-Based Lightweight Testbed for Supporting Network Security Hands-on Labs.',\n",
       "  'A bounded diameter minimum spanning tree evolutionary algorithm based on double chromosome.',\n",
       "  'A nationwide census on wifi security threats: prevalence, riskiness, and the economics.',\n",
       "  'A new hyperspectral band selection approach based on convolutional neural network.',\n",
       "  'A novel RFID and capacitive sensing based smart bookshelf.',\n",
       "  'Accuracy of a Novel Parallel Robot with Orthogonal Chains.',\n",
       "  'Acronym extraction and disambiguation in large-scale organizational web pages.',\n",
       "  'Adaptive Graph Planning Protocol: An Adaption Approach to Collaboration in Open Multi-agent Systems.',\n",
       "  'Adaptive Modulation and Coding Technology in 5G System.',\n",
       "  'Adaptive power management using reinforcement learning.',\n",
       "  'An Application of Bag Filter Control System Based on Techniques of OPC and Multibus.',\n",
       "  'An Automatic Detection Algorithm for Surface Defects in TFT-LCD.',\n",
       "  'An Effective Road Extraction Method from Remote Sensing Images Based on Self-Adaptive Threshold Function.',\n",
       "  'An Encoding Strategy Based Word-Character LSTM for Chinese NER.',\n",
       "  'An Event Ontology Description Framework Based on SKOS.',\n",
       "  'An Extension of DTFT-Based Sinusoidal Signal Time Delay Estimation Algorithm for Linear Time-Varying Situation.',\n",
       "  'An Improved Puncturing Scheme for Polar Codes.',\n",
       "  'An Ontology Pattern for Emergency Event Modeling.',\n",
       "  'An analysis of research on tourism information technology: The case of ENTER proceedings.',\n",
       "  'An analytic algorithm based electromagnetic localization method.',\n",
       "  \"Analysis on China's Capital Market Form through Hurst Exponent.\",\n",
       "  'Application of Emotional Recognition in Intelligent Tutoring System.',\n",
       "  'Application specific sensor node architecture optimization - Experiences from field deployments.',\n",
       "  'Australian Neuroinformatics Research - Grid Computing and e-Research.',\n",
       "  'Automatic diagnosis of multiple lesions in fundus images based on dual attention mechanism.',\n",
       "  'Average Fuzzy Direction Based Handwritten Chinese Characters Recognition Approach.',\n",
       "  'Balance of memory footprint and runtime for high-density routing in large-scale FPGAs.',\n",
       "  'Bringing interaction design methods and experimental technologies together into designing and developing interactive products.',\n",
       "  'CA-2D-VLC Decoder for AVS in SOC Design.',\n",
       "  'CIST@CLSciSumm-19: Automatic Scientific Paper Summarization with Citances and Facets.',\n",
       "  'Chinese Event Detection Based on Event Ontology and Siamese Network.',\n",
       "  'Chinese Street View Text: Large-Scale Chinese Text Reading With Partially Supervised Learning.',\n",
       "  'Classification of Computerized Tomography Images of Endemic Liver Hydatid in Xinjiang Based on Decision Tree.',\n",
       "  'Clustering Ensemble Selection with Analytic Hierarchy Process.',\n",
       "  'Clustering Ensemble Selection with Determinantal Point Processes.',\n",
       "  'Comprehensive Evaluation Model of Service Robot.',\n",
       "  'Compression of proteome gel images using complex wavelet transform.',\n",
       "  'Computation offloading for sporadic real-time tasks.',\n",
       "  'Computing the set of concepts through the composition and decomposition of formal contexts.',\n",
       "  'Context Aware Community Formation for MAS-Oriented Collective Adaptive System.',\n",
       "  'Continuous Authentication of Mouse Dynamics Based on Decision Level Fusion.',\n",
       "  'Contour Knowledge Transfer for Salient Object Detection.',\n",
       "  'Contours-Matching in Building Reconstruction from a Single Image.',\n",
       "  'Coverage Optimization of Mobile Sensor Networks Based Improved Beetle Antennae Search Algorithm.',\n",
       "  'Creating Multi-domain Query Plans on Data Services.',\n",
       "  'DarkJargon.net: A Platform for Understanding Underground Conversation with Latent Meaning.',\n",
       "  'Deep Reinforcement Learning-Based MEC Offloading and Resource Allocation in Uplink NOMA Heterogeneous Network.',\n",
       "  'Design Optimization under Aleatory and Epistemic Uncertainties.',\n",
       "  \"Design and System Realization of the Evaluation Index of Learners' Core Literacy Ability Based on STEAM Education.\",\n",
       "  'Design and implementation of a new web anti-attack method based on URL randomization.',\n",
       "  'Design of Multiple-Tau Photon Correlation System Implemented by FPGA.',\n",
       "  'Development of MEMS Capacitive Mirror Structure with CMOS Compatible Process.',\n",
       "  'Development of Timing Node on EAST Neutral Beam Injector.',\n",
       "  'Development of monitoring system of infrared thermometer for neutral beam injector on EAST.',\n",
       "  'Development of three dimensional digital tourism presentation system based on Google Earth API.',\n",
       "  'Distilled Wasserstein Learning for Word Embedding and Topic Modeling.',\n",
       "  'Distributed Simulation System Based on Data Distribution Service Standard.',\n",
       "  'Distributed policy enforcement for priority awareness in tactical SATCOM networks.',\n",
       "  'Duplicate Identification in Deep Web Data Integration.',\n",
       "  'Duty Cycle Optimization for Blood Pressure Sensors in Wireless Body Area Networks Based on Reinforcement Learning.',\n",
       "  'Dynamic Forest Model for Sentiment Classification.',\n",
       "  'Efficient Genetic Algorithm for High-Dimensional Function Optimization.',\n",
       "  'Energy Efficiency Optimization Based on Context Awareness in Wearable Computing.',\n",
       "  'Event Relation Reasoning Based on Event Knowledge Graph.',\n",
       "  'Experimental investigation of vibration and transmitted power for vehicle rear axle noise research.',\n",
       "  'Experimental modeling of magneto-rheological damper and PID neural network controller design.',\n",
       "  'Exploring SSD endurance model based on write amplification and temperature.',\n",
       "  'Eye-tracking Based Performance Analysis in Error Finding Programming Test.',\n",
       "  'Fabrication, Characterization and Modeling of CVD based Amorphous Silicon Resistor.',\n",
       "  'Fast Communication-Aware Virtual Machine Dynamic Consolidation for Cloud Data Center.',\n",
       "  'Fault Analysis of Condenser Based on RBF Network and D-S Evidence Theory.',\n",
       "  'Fault Diagnosis Method of Aeroengine Bearing Based on Convolution Self-Coded Neural Network.',\n",
       "  'Fault Diagnosis of a PEM Fuel Cell System by SP Model and On-line Expert Systems Techniques.',\n",
       "  'Fault-Tolerating Edge Computing with Server Redundancy Based on a Variant of Group Degree Centrality.',\n",
       "  'Feature Extraction and Classification of Xinjiang High Morbidity Esophageal Cancer Based on Tamura and Wavelet Transform.',\n",
       "  'Feature fusion of HOG and WLD for facial expression recognition.',\n",
       "  'Forensic Detection Based on Color Label and Oriented Texture Feature.',\n",
       "  'From Text to Sound: A Preliminary Study on Retrieving Sound Effects to Radio Stories.',\n",
       "  'Generalized Inverse Matrix A+ and Solution of Linear Equation Group.',\n",
       "  'Geologic Body Classification of Hyperspectral Data Based on Dilated Convolution Neural Network at Tianshan Area.',\n",
       "  'Graph-Based Equivalence Concept Matching in Knowledge Organization System Integration: A Case Study on Thesaurus.',\n",
       "  'Hierarchical Multi-dimensional Attention Model for Answer Selection.',\n",
       "  'High-throughput HW-SW implementation for MV-HEVC decoder.',\n",
       "  'Image Fusion Based on PCA and Undecimated Discrete Wavelet Transform.',\n",
       "  'Importance-Based Web Page Classification Using Cost-Sensitive SVM.',\n",
       "  'Improved Kriging Interpolation Based on Support Vector Machine and Its Application in Oceanic Missing Data Recovery.',\n",
       "  'Improving scalability in QoS guarantee MN to MN mobile communication using traffic engineered MPLS path.',\n",
       "  'Intelligent Layout Design for Complex Mechatronic Products Based on Distributed Knowledge.',\n",
       "  'Interactive Chinese Search Results Clustering for Personalization.',\n",
       "  'JCDTA: The Data Trading Archtecture Design in JointCloud Computing.',\n",
       "  'Joint Offloading and Computation Resource Allocation in D2D Assisted Hybrid Framework.',\n",
       "  'Kernel low-rank representation for hyperspectral image classification.',\n",
       "  'Knowledge Graph Embedding Preserving Soft Logical Regularity.',\n",
       "  'Large Eddy Simulation of Virus Transport Around Buildings.',\n",
       "  'Large-Scale Land Cover Mapping of Satellite Images Using Ensemble of Random Forests - IEEE Data Fusion Contest 2020 Track 1.',\n",
       "  'Large-Scale Land Cover Mapping of Satellite Images Using Ensemble of Random Forests with Multi-Resolution Label - IEEE Data Fusion Contest 2020 Track 2.',\n",
       "  'Leveraging Long-Range Temporal Relationships Between Proposals for Video Object Detection.',\n",
       "  'Leveraging Social Networks to Enhance Effective Coverage for Mobile Crowdsensing.',\n",
       "  'Lexicon Enhanced Chinese Sequence Labeling Using BERT Adapter.',\n",
       "  'Log-Based Control Flow Attestation for Embedded Devices.',\n",
       "  'MSA vs. MVC: Future Trends for Big Data Processing Platforms.',\n",
       "  'Make the Future Visible Today!: A Reflection on Using Design Thinking and Futures Studies Techniques to Foster Creativity.',\n",
       "  'Markerless tracking for augmented reality applied in reconstruction of Yuanmingyuan archaeological site.',\n",
       "  'Memory-Centric Communication Mechanism for Real-time Autonomous Navigation Applications.',\n",
       "  'Mobile Terminals Haptic Interface: A Vibro-Tactile Finger Device for 3D Shape Rendering.',\n",
       "  'Model updating applied to an missile structure.',\n",
       "  'Multi-point Cooperative Fountain Codes Multicast for LTE Cellular System.',\n",
       "  'Multi-view Emotion Recognition Using Deep Canonical Correlation Analysis.',\n",
       "  'Multimodal Emotion Recognition Using Deep Generalized Canonical Correlation Analysis with an Attention Mechanism.',\n",
       "  'Multimodal Emotion Recognition Using a Modified Dense Co-Attention Symmetric Network.',\n",
       "  'Multiple Energy Harvesting Devices Enabled Joint Computation Offloading and Dynamic Resource Allocation for Mobile-Edge Computing Systems.',\n",
       "  'Multiple features fusion for hyperspectral image classification based on extreme learning machine.',\n",
       "  'Near-Data Processing-Enabled and Time-Aware Compaction Optimization for LSM-tree-based Key-Value Stores.',\n",
       "  'Noninvasive Blood Pressure Classification based on ECG with ResNet Algorithm.',\n",
       "  'Obstacle avoidance for quadrotor using improved method based on optical flow.',\n",
       "  'On-chip hybrid power supply system for wireless sensor nodes.',\n",
       "  'Ontology-Based Integration and Sharing of Big Data Educational Resources.',\n",
       "  'Optimization of ride comfort and handing stability base on virtual prototyping.',\n",
       "  'PAAP: prefetch-aware admission policies for query results cache in web search engines.',\n",
       "  'PCA-Aware Anomaly Correction for Traffic Matrix in an IP Backbone Network.',\n",
       "  'Pairwise Stereo Image Disparity and Semantics Estimation with the Combination of U-Net and Pyramid Stereo Matching Network.',\n",
       "  'Particle swarm optimization-based wavelet packet regression for multivariate analysis of near-infrared spectroscopy.',\n",
       "  'Path Planning for Mobile Robot Based on Improved Framed-Quadtree.',\n",
       "  'Performance analysis of polarization coding BB84 quantum key distribution system under non-Markovian channel.',\n",
       "  'Personalized Reputation Model in Cooperative Distributed Systems.',\n",
       "  'PointPWC-Net: Cost Volume on Point Clouds for (Self-)Supervised Scene Flow Estimation.',\n",
       "  'QoE Aware and Cell Capacity Enhanced Computation Offloading for Multi-Server Mobile Edge Computing Systems with Energy Harvesting Devices.',\n",
       "  'RSFP: Reliable Service Function Placement with Optimized Resource Consumption in Data Center Networks.',\n",
       "  'Radio map position inference algorithm for indoor positioning systems.',\n",
       "  'RandMap: Wear Level for Phase Change Memory Based on Layer-Based Random Mapping.',\n",
       "  'Recognition of staphylococcus aureus by new carborane derivative.',\n",
       "  'Requirements Planning with Event Calculus for Runtime Self-Adaptive System.',\n",
       "  'Research on Diagnosing Heart Disease Using Adaptive Network-based Fuzzy Interferences System.',\n",
       "  'Research on High Availability Mechanism in Distributed Data Stream Management System.',\n",
       "  'Research on Particle Swarm Optimization and its Industrial Application.',\n",
       "  'Research on Teaching Quality Evaluation of Online Education Courses Based on Multiple Intelligence.',\n",
       "  'Research on construction of smart medical system based on the social security card.',\n",
       "  'Research on insect identification based on pattern recognition technology.',\n",
       "  'Retweeting Behavior Prediction Based on One-Class Collaborative Filtering in Social Networks.',\n",
       "  'Robustness analysis for three-dimensional node localization in wireless sensor networks.',\n",
       "  'SARSA-Based CoAP Mode and Route Selection Joint Optimization in Power Underground Pipe Gallery.',\n",
       "  'Semantic 3D Reconstruction Using Multi-View High-Resolution Satellite Images Based on U-Net and Image-Guided Depth Fusion.',\n",
       "  'Semantic and Morphological Information Guided Chinese Text Classification.',\n",
       "  'Semi-Supervised Classification of Hyperspectral Data Based on Generative Adversarial Networks and Neighborhood Majority Voting.',\n",
       "  'Semi-Supervised Classification of Hyperspectral Data for Geologic Body Based on Generative Adversarial Networks at Tianshan Area.',\n",
       "  'Semi-supervised Sentiment Classification Method Based on Weibo Social Relationship.',\n",
       "  'Sequential Boosting for Learning a Random Forest Classifier.',\n",
       "  'Service Capacity Enhanced Task Offloading and Resource Allocation in Multi-Server Edge Computing Environment.',\n",
       "  'Spatial Feature Aware Genetic Algorithm of Network Base Station Configuration for Internet of Things.',\n",
       "  'Spectrum aggregation based spectrum allocation for cognitive radio networks.',\n",
       "  'Splog Filtering Based on Writing Consistency.',\n",
       "  'Sports Information Extraction and Presentation.',\n",
       "  'Statistical evaluation of fitting models of diffusion tensor imaging in characterizing normal porcine myocardium.',\n",
       "  'Student Performance Prediction by LMS Data and Classroom Videos.',\n",
       "  'Study of ride comfort of active suspension based on model reference neural network control system.',\n",
       "  'Team Water: The Champion of the RoboCup Middle Size League Competition 2013.',\n",
       "  'The Design of Smart Female Brassiere Based on CurieNeurons Technology for Monitoring Mild Depression.',\n",
       "  'The Detection and Recognition of Pulmonary Nodules Based on U-net and CNN.',\n",
       "  'The Detection and Segmentation of Pulmonary Nodules Based on U-Net.',\n",
       "  'The Nature of Block Chain Intelligent Contract.',\n",
       "  'The design of smart home platform based on Cloud Computing.',\n",
       "  'The effect of age and native speaker status on synthetic speech intelligibility.',\n",
       "  'Towards Efficient Lesion Localization Based on Template Occlusion Strategy in Intelligent Diagnosis.',\n",
       "  'Towards Playing Full MOBA Games with Deep Reinforcement Learning.',\n",
       "  'Traffic congestion identification based on parallel SVM.',\n",
       "  'Two methods for estimating noise amplitude spectral in non-stationary environments.',\n",
       "  'Two-factor Protection Scheme in Securing the Source Code of Android Applications.',\n",
       "  'Understanding and modeling the Deep Web for integrated environment.',\n",
       "  'UniKeyphrase: A Unified Extraction and Generation Framework for Keyphrase Prediction.',\n",
       "  'VLD Design for AVS Video Decoder.',\n",
       "  'Ventilation system design and rotor air friction loss of high-speed permanent magnet machines.',\n",
       "  'Wavelet-Based Noise Reduction in Power Analysis Attack.',\n",
       "  'Weibo User Influence Evaluation Method Based on Topic and Node Attributes.',\n",
       "  'Wikipedia-Graph Based Key Concept Extraction towards News Analysis.'}}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_graph.nodes[\"Wei Liu\"]\n",
    "nx.write_gml(author_graph, \"author_graph.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read graphml back into networkX graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_graph = nx.read_graphml(\"author_graph.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mail4\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "count = 0\n",
    "for i in range(len(df)):\n",
    "    if df[\"Author\"][i] == \"Thomas Seidl 0001\":\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "author_graph = nx.read_graphml(\"author_graph.graphml\")\n",
    "authors = df[\"Author\"]\n",
    "author_list = authors.sample(500)\n",
    "subgraph = author_graph.subgraph(author_list)\n",
    "nx.draw(subgraph, with_labels = True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8ad7cc9a111ac577fec804d99d295f3f6da60a5d648a58c5540db810996fd30"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
