{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do:\n",
    "- figure out how to save graph locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### references:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing: sys.stdout.write(f'\\r  ...progress: {curRow * tilesY} / {tilesX * tilesY} ({pct:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from lxml.etree import XMLSyntaxError\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import networkx as nx\n",
    "from natsort import index_natsorted, order_by_index\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  progress:  1000000  rows\n",
      "broke\n"
     ]
    }
   ],
   "source": [
    "source = \"dblp.xml\" #dataset of publications\n",
    "dtd = etree.DTD(file=\"dblp.dtd\") #read DTD\n",
    "publication_data = [] #fill this list with pairs of author/title\n",
    "counter = 0\n",
    "bad_titles = [\"Home Page\", \"Title Page\", \"Welcome message.\", \"Workshop preface.\", \"Vorwort.\", \"The\", \"The \", \"Session Summary.\", \"Reviewers.\", \"Program Committee.\", \n",
    "    \"Preface.\", \"Organizing Committee.\", \"Workshop Organization.\", \"Workshop Organizers' Message.\", \"Title Page.\", \"Steering Committee.\", \"Session details: Keynote Address.\",\n",
    "    \"S\"]\n",
    "#iterate through nodes\n",
    "for event, element in etree.iterparse(source, load_dtd=True):\n",
    "    title = \"\"\n",
    "    author_list = []\n",
    "    year = 0\n",
    "    #iterate through children: author, title, year, etc.\n",
    "    for child in element:\n",
    "        if child.tag == \"author\":\n",
    "            counter+=1\n",
    "        elif child.tag == \"title\":\n",
    "            title = str(child.text)\n",
    "            if title in bad_titles:\n",
    "                title = \"\";\n",
    "            # break\n",
    "    if counter % 10000 == 0:\n",
    "        sys.stdout.write(f'\\r  progress:  {counter}  rows')\n",
    "    if counter >= 1000000:\n",
    "        print(\"\\nbroke\")\n",
    "        break\n",
    "#create dataframe\n",
    "publication_df = pd.DataFrame(publication_data)\n",
    "\n",
    "element.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  progress:  1000000  rows\n",
      "broke\n"
     ]
    }
   ],
   "source": [
    "source = \"dblp.xml\" #dataset of publications\n",
    "dtd = etree.DTD(file=\"dblp.dtd\") #read DTD\n",
    "publication_data = [] #fill this list with pairs of author/title\n",
    "edge_list = [] #fill this with edges\n",
    "counter = 0\n",
    "bad_titles = [\"Home Page\", \"Title Page\", \"Welcome message.\", \"Workshop preface.\", \"Vorwort.\", \"The\", \"The \", \"Session Summary.\", \"Reviewers.\", \"Program Committee.\", \n",
    "    \"Preface.\", \"Organizing Committee.\", \"Workshop Organization.\", \"Workshop Organizers' Message.\", \"Title Page.\", \"Steering Committee.\", \"Session details: Keynote Address.\",\n",
    "    \"S\"]\n",
    "#iterate through nodes\n",
    "for event, element in etree.iterparse(source, load_dtd=True):\n",
    "    title = \"\"\n",
    "    author_list = []\n",
    "    year = 0\n",
    "    #iterate through children: author, title, year, etc.\n",
    "    for child in element:\n",
    "        if child.tag == \"author\":\n",
    "            author_list.append(str(child.text))\n",
    "        elif child.tag == \"title\":\n",
    "            title = str(child.text)\n",
    "            if title in bad_titles:\n",
    "                title = \"\"; \n",
    "        elif child.tag == \"year\":\n",
    "            year = int(child.text)\n",
    "            for author in author_list:\n",
    "                publication_data.append({\"Author\" : author.strip(), \"Title\" : title.strip(), \"Year\" : year}) #add author/title/year pair to data list\n",
    "            if len(author_list) > 1:\n",
    "                edge_list.append(author_list)\n",
    "            counter += 1\n",
    "            break\n",
    "    if counter % 10000 == 0:\n",
    "        sys.stdout.write(f'\\r  progress:  {counter}  rows')\n",
    "    if counter > 1000000:\n",
    "        print(\"\\nbroke\")\n",
    "        break\n",
    "#create dataframe\n",
    "publication_df = pd.DataFrame(publication_data)\n",
    "edges_df = pd.DataFrame(edge_list)\n",
    "element.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2951916</th>\n",
       "      <td>Christoph Tögel</td>\n",
       "      <td>The Effects of Full-Body Avatar Movement Predi...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951917</th>\n",
       "      <td>Julian Dietz</td>\n",
       "      <td>The Effects of Full-Body Avatar Movement Predi...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951918</th>\n",
       "      <td>Niels Henze</td>\n",
       "      <td>The Effects of Full-Body Avatar Movement Predi...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951919</th>\n",
       "      <td>Simon Stannus</td>\n",
       "      <td>Natural 7DoF navigation &amp; interaction in 3D ge...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951920</th>\n",
       "      <td>Arko Lucieer</td>\n",
       "      <td>Natural 7DoF navigation &amp; interaction in 3D ge...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951921</th>\n",
       "      <td>Wai-Tat Fu</td>\n",
       "      <td>Natural 7DoF navigation &amp; interaction in 3D ge...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951922</th>\n",
       "      <td>Kaisa Kauppinen</td>\n",
       "      <td>Producing identity in collaborative virtual en...</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951923</th>\n",
       "      <td>Anri Kivimäki</td>\n",
       "      <td>Producing identity in collaborative virtual en...</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951924</th>\n",
       "      <td>Taina Era</td>\n",
       "      <td>Producing identity in collaborative virtual en...</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951925</th>\n",
       "      <td>Mike Robinson</td>\n",
       "      <td>Producing identity in collaborative virtual en...</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Author                                              Title  \\\n",
       "2951916  Christoph Tögel  The Effects of Full-Body Avatar Movement Predi...   \n",
       "2951917     Julian Dietz  The Effects of Full-Body Avatar Movement Predi...   \n",
       "2951918      Niels Henze  The Effects of Full-Body Avatar Movement Predi...   \n",
       "2951919    Simon Stannus  Natural 7DoF navigation & interaction in 3D ge...   \n",
       "2951920     Arko Lucieer  Natural 7DoF navigation & interaction in 3D ge...   \n",
       "2951921       Wai-Tat Fu  Natural 7DoF navigation & interaction in 3D ge...   \n",
       "2951922  Kaisa Kauppinen  Producing identity in collaborative virtual en...   \n",
       "2951923    Anri Kivimäki  Producing identity in collaborative virtual en...   \n",
       "2951924        Taina Era  Producing identity in collaborative virtual en...   \n",
       "2951925    Mike Robinson  Producing identity in collaborative virtual en...   \n",
       "\n",
       "         Year  \n",
       "2951916  2020  \n",
       "2951917  2020  \n",
       "2951918  2020  \n",
       "2951919  2014  \n",
       "2951920  2014  \n",
       "2951921  2014  \n",
       "2951922  1998  \n",
       "2951923  1998  \n",
       "2951924  1998  \n",
       "2951925  1998  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publication_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2951926\n",
      "777398\n"
     ]
    }
   ],
   "source": [
    "publication_df.to_csv('data.csv')\n",
    "edges_df.to_csv('edges.csv')\n",
    "print(len(publication_df))\n",
    "print(len(edges_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting CSV to graph: adding authors as nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_df = pd.read_csv(\"data.csv\")\n",
    "publication_df = publication_df.reindex(index=order_by_index(publication_df.index, index_natsorted(publication_df['Author'], reverse=False))) # sorting by author name\n",
    "publication_df.to_csv('data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique authors: 965885\n"
     ]
    }
   ],
   "source": [
    "author_graph = nx.Graph()\n",
    "publication_df = pd.read_csv(\"data.csv\")\n",
    "author_graph.add_node(publication_df[\"Author\"][0], Publications = {publication_df[\"Title\"][0]})\n",
    "for row in range(1, len(publication_df)):\n",
    "    author = publication_df[\"Author\"][row]\n",
    "    if author == publication_df[\"Author\"][row-1]:\n",
    "        author_graph.nodes[author][\"Publications\"].add(publication_df[\"Title\"][row]) #adding title to list of publications from that author\n",
    "    else:\n",
    "        author_graph.add_node(author, Publications = {publication_df[\"Title\"][row]}) #adding author to graph with title to attibute\n",
    "print(\"Number of unique authors: \" + str(len(author_graph.nodes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting CSV by title and url (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mail4\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "publication_df1 = pd.read_csv(\"data.csv\")\n",
    "# publication_df1 = publication_df1.reindex(index=order_by_index(publication_df1.index, index_natsorted(publication_df1['Url'], reverse=False)))\n",
    "publication_df1 = publication_df1.reindex(index=order_by_index(publication_df1.index, index_natsorted(publication_df1['Title'], reverse=True)))\n",
    "publication_df1.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding edges for authors that share title (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 0\n",
    "while (publication_df[\"Title\"][row] != \"None\"): #for all elements with a title\n",
    "# while row < len(publication_df2)-5:\n",
    "    next = 1\n",
    "    current_author = publication_df[\"Author\"][row]\n",
    "    co_authors = [current_author] #list of coauthors\n",
    "    while publication_df[\"Title\"][row] ==  publication_df[\"Title\"][row + next]: #find all authors with same title\n",
    "        if (current_author !=  publication_df[\"Author\"][row + next]) and (publication_df2[\"Year\"][row] ==  publication_df[\"Year\"][row + next]): #make sure no edges between same author\n",
    "            co_authors.append(publication_df[\"Author\"][row + next]) #add to list of co-authors\n",
    "            print(publication_df[\"Title\"][row])\n",
    "        next += 1\n",
    "    author_graph.add_edges_from(list(combinations(co_authors, 2))) #add edges between all coauthors\n",
    "    row += 1\n",
    "print(\"Last row with a title: \" + str(row))\n",
    "print(\"Number of edges: \" + str(len(author_graph.edges)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding edges for authors that share URL (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 566\n"
     ]
    }
   ],
   "source": [
    "row = 352356\n",
    "while row < len(publication_df) - 1: #for all elements with no title\n",
    "    next = 1\n",
    "    co_authors = [publication_df[\"Author\"][row]] #list of coauthors\n",
    "    while publication_df[\"Url\"][row] ==  publication_df[\"Url\"][row + next]: #find all authors with same title\n",
    "        if (publication_df[\"Author\"][row] !=  publication_df[\"Author\"][row + next]) and (publication_df2[\"Year\"][row] ==  publication_df[\"Year\"][row + next]): #make sure no edges between same author\n",
    "            co_authors.append(publication_df[\"Author\"][row + next]) #add to list of co-authors\n",
    "        next += 1\n",
    "    author_graph.add_edges_from(list(combinations(co_authors, 2))) #add edges between all coauthors\n",
    "    row += 1\n",
    "print(\"Number of edges: \" + str(len(author_graph.edges)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding edges based on CSV of edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mail4\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "edges_list = pd.read_csv(\"edges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[(1, 2), (1, 3), (2, 3)]\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from([1, 2, 3])\n",
    "print(G.nodes)\n",
    "G.add_edges_from(list(combinations([1, 2, 3], 2)))\n",
    "print(G.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  rows processed: 770000"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for row in edges_list.iterrows():\n",
    "    i = 1\n",
    "    coauthors = []\n",
    "    while (type(row[1][i])) == str and (i < 15):\n",
    "        coauthors.append(row[1][i])\n",
    "        i += 1\n",
    "    author_graph.add_edges_from(list(combinations(coauthors, 2)))\n",
    "    count+=1\n",
    "    if count % 10000 == 0:\n",
    "        sys.stdout.write(f'\\r  rows processed: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Wei Wang', 771), ('Yang Liu', 727), ('Wei Zhang', 653), ('Wei Li', 650), ('Lei Zhang', 626), ('Lei Wang', 621), ('Xin Li', 617), ('Jing Li', 610), ('Wei Liu', 608), ('Xin Wang', 595)]\n",
      "\n",
      "['Bülent Abali', 'Bülent Bolat', 'Bülent Çatay', 'Bülent Dal', 'Bülent Durak', 'Bülent Haznedar', 'Bülent Karasözen', 'Bülent Keskinler', 'Bülent Möller', 'Bülent Örencik']\n"
     ]
    }
   ],
   "source": [
    "print(str(sorted(author_graph.degree, key=lambda x: x[1], reverse=True)[0:10]) + \"\\n\") # 10 authors with most coauthors\n",
    "\n",
    "# google pagerank algorithm (error with this)\n",
    "pageranks = nx.pagerank(author_graph) # A dictionary\n",
    "print(sorted(pageranks, key=lambda x: x[1], reverse=True)[0:10]) # 10 authors with highest pageranks score (sharing publications with more important authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save graph as a gpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(author_graph, \"author_graph.gpickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read gpickle back into networkX graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_graph = nx.read_gpickle(\"author_graph.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_graph = nx.read_gpickle(\"author_graph.gpickle\")\n",
    "author_list = list(nx.dfs_preorder_nodes(author_graph, source=0, depth_limit=2))\n",
    "subgraph = author_graph.subgraph(author_list)\n",
    "nx.draw(subgraph, with_labels = True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8ad7cc9a111ac577fec804d99d295f3f6da60a5d648a58c5540db810996fd30"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
